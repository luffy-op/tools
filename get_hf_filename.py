import requests
from bs4 import BeautifulSoup
import time

BASE_URL = "https://hf-mirror.com"
REPO = "stabilityai/stable-diffusion-2-1-base"
BRANCH = "main"

visited = set()

def get_full_url(path):
    return f"{BASE_URL}/{REPO}/tree/{BRANCH}/{path}".rstrip('/')

def get_files_recursive(path=""):
    url = get_full_url(path)
    if url in visited:
        return []
    visited.add(url)

    print(f"ğŸ“‚ æ­£åœ¨è®¿é—®: {url}")
    time.sleep(0.5)  # é™é€Ÿï¼Œé˜²æ­¢å°ç¦

    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        print(f"âš ï¸ è®¿é—®å¤±è´¥: {url}ï¼ŒçŠ¶æ€ç  {res.status_code}")
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    files = []

    # æŸ¥æ‰¾æ‰€æœ‰ <a href=...>
    for link in soup.find_all("a", href=True):
        href = link["href"]

        # æ˜¯æ–‡ä»¶
        if f"/blob/{BRANCH}/" in href:
            file_path = href.split(f"/blob/{BRANCH}/")[-1]
            files.append(file_path)

        # æ˜¯å­ç›®å½•
        elif f"/tree/{BRANCH}/" in href:
            folder_path = href.split(f"/tree/{BRANCH}/")[-1]
            if folder_path not in visited:
                files.extend(get_files_recursive(folder_path))

    return files

# è¿è¡Œ
all_files = get_files_recursive()
print("\nğŸ“œ ä»“åº“ä¸­æ‰€æœ‰æ–‡ä»¶è·¯å¾„ï¼š")
for f in sorted(set(all_files)):
    print(f)
